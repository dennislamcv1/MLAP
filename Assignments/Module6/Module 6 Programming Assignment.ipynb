{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3a3dc60178c7c588d0f7bf220d5ae5e",
     "grade": false,
     "grade_id": "cell-9fe3edd84ede6fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Module 6 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Run the first code cell to import modules needed by this assignment before proceeding to problems.\n",
    "2. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "3. Each problem has an autograder cell below the answer cell. Run the autograder cell to check your answer. If there's anything wrong in your answer, the autograder cell will display error messages.\n",
    "4. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and Restart & Run all. If the notebook runs through the last code cell without an error message, you've answered all problems correctly.\n",
    "5. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47e45c5a2e283a97e5474d0589595ce8",
     "grade": false,
     "grade_id": "cell-31752648086a10b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Run Me First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76c484feaa9128a5b35c7165fc3ca67a",
     "grade": false,
     "grade_id": "cell-88dd2a72c7ccd97d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance\n",
    "\n",
    "# We do this to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4744a7aebbd0b92b594c4a0d9a9f888",
     "grade": false,
     "grade_id": "cell-c36036bd06797824",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Prepare Yelp Review Data\n",
    "\n",
    "In this assignment, you will use the Yelp review dataset. Before we attempt to build a model, we first prepare the data.\n",
    "\n",
    "The Yelp review dataset contains 1000 customer reviews of a group of restaurants. There are two columns in the dataset, column **stars** which is the star rating and column __text__ which is the review text. The dataset only contains 1-star and 5-star reviews. There are 500 1-star reviews and 500 5-star reviews.\n",
    "\n",
    "Please run the next Code cell before proceeding to Problem 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f81e0e7febab81c66d1a883402d5444",
     "grade": false,
     "grade_id": "cell-b7a411e93e83fc6a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Reviews by Star Rating:\n",
      "5    500\n",
      "1    500\n",
      "Name: stars, dtype: int64\n",
      "\n",
      "Sample Review(5 stars):\n",
      "I love love LOVE this place. My boss (who is into healthy eating) recommended this place. I went over with some highly skeptical friends and one dinner was enough to convert them into believers! The food here is so good! We had the Shrimp dumplings and the Onion tart as starters. We ordered the Shirataki noodles and street tacos as entrees. So also ordered the Kale-aid. All of the dishes were yummy. \n",
      "I have gone back many times since then and have never been disappointed! I have gone after yoga to get some Kale salad or the chicken chopped salad. I always have to get the Kale aid. \n",
      "Once, a guy at the next table, uprooted a whole plant by mistake (on the patio) and was highly embarrassed as was his date! Ever since, I have very careful not to throw my arms around as I can be quite clumsy sometimes! I do NOT want to be banned from my favorite place for my clumsiness! I don't think I can live without True Food!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Dataset Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>Celebrated my anniversary here. Everything was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>I had such high expectaions after reading revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stars                                               text\n",
       "37       5  Celebrated my anniversary here. Everything was...\n",
       "726      1  I had such high expectaions after reading revi..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load yelp review dataset\n",
    "df = pd.read_csv('data/yelp_reviews.csv')\n",
    "rating = df['stars']\n",
    "data = df['text']\n",
    "sample_review = data[0]\n",
    "print(f'Counts of Reviews by Star Rating:\\n{rating.value_counts()}\\n')\n",
    "print(f'Sample Review({rating[0]} stars):\\n{sample_review}')\n",
    "print('-'*80)\n",
    "print('\\nDataset Sample:')\n",
    "df.sample(2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem 1: Get Top Words from a Sample Review\n",
    "\n",
    "Get the most-used words in a sample review.\n",
    "\n",
    "For this problem you will use the string **sample_review** created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Use regular expression `r'[^\\w]'` to replace all characters in sample_review that are not letter or number with white spaces, assign the new string to sample_review_ns.\n",
    "- Convert sample_review_ns to **all lower case** with string function lower(), assign the new string to sample_review_nsl.\n",
    "- Use string function split() to split sample_review_nsl to a list of words and use the list to construct a `Counter` object in `collections` module.\n",
    "- Get **top 10** words from the Counter object with `most_common()` function and assign the result to variable __top_10_words__.\n",
    "\n",
    "After this problem, there's a new variable **top_10_words** defined.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ce6ff163b02a4bee7feb8dc06d12e9",
     "grade": false,
     "grade_id": "p1-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import collections as cl\n",
    "\n",
    "# YOUR CODE HERE\n",
    "sample_review_ns = re.sub(r'[^\\w]',' ',sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love love LOVE this place  My boss  who is into healthy eating  recommended this place  I went over with some highly skeptical friends and one dinner was enough to convert them into believers  The food here is so good  We had the Shrimp dumplings and the Onion tart as starters  We ordered the Shirataki noodles and street tacos as entrees  So also ordered the Kale aid  All of the dishes were yummy   I have gone back many times since then and have never been disappointed  I have gone after yoga to get some Kale salad or the chicken chopped salad  I always have to get the Kale aid   Once  a guy at the next table  uprooted a whole plant by mistake  on the patio  and was highly embarrassed as was his date  Ever since  I have very careful not to throw my arms around as I can be quite clumsy sometimes  I do NOT want to be banned from my favorite place for my clumsiness  I don t think I can live without True Food '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review_nsl = sample_review_ns.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love love love this place  my boss  who is into healthy eating  recommended this place  i went over with some highly skeptical friends and one dinner was enough to convert them into believers  the food here is so good  we had the shrimp dumplings and the onion tart as starters  we ordered the shirataki noodles and street tacos as entrees  so also ordered the kale aid  all of the dishes were yummy   i have gone back many times since then and have never been disappointed  i have gone after yoga to get some kale salad or the chicken chopped salad  i always have to get the kale aid   once  a guy at the next table  uprooted a whole plant by mistake  on the patio  and was highly embarrassed as was his date  ever since  i have very careful not to throw my arms around as i can be quite clumsy sometimes  i do not want to be banned from my favorite place for my clumsiness  i don t think i can live without true food '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_nsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sample_review_nsl.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'love', 'love', 'this', 'place', 'my', 'boss', 'who', 'is', 'into', 'healthy', 'eating', 'recommended', 'this', 'place', 'i', 'went', 'over', 'with', 'some', 'highly', 'skeptical', 'friends', 'and', 'one', 'dinner', 'was', 'enough', 'to', 'convert', 'them', 'into', 'believers', 'the', 'food', 'here', 'is', 'so', 'good', 'we', 'had', 'the', 'shrimp', 'dumplings', 'and', 'the', 'onion', 'tart', 'as', 'starters', 'we', 'ordered', 'the', 'shirataki', 'noodles', 'and', 'street', 'tacos', 'as', 'entrees', 'so', 'also', 'ordered', 'the', 'kale', 'aid', 'all', 'of', 'the', 'dishes', 'were', 'yummy', 'i', 'have', 'gone', 'back', 'many', 'times', 'since', 'then', 'and', 'have', 'never', 'been', 'disappointed', 'i', 'have', 'gone', 'after', 'yoga', 'to', 'get', 'some', 'kale', 'salad', 'or', 'the', 'chicken', 'chopped', 'salad', 'i', 'always', 'have', 'to', 'get', 'the', 'kale', 'aid', 'once', 'a', 'guy', 'at', 'the', 'next', 'table', 'uprooted', 'a', 'whole', 'plant', 'by', 'mistake', 'on', 'the', 'patio', 'and', 'was', 'highly', 'embarrassed', 'as', 'was', 'his', 'date', 'ever', 'since', 'i', 'have', 'very', 'careful', 'not', 'to', 'throw', 'my', 'arms', 'around', 'as', 'i', 'can', 'be', 'quite', 'clumsy', 'sometimes', 'i', 'do', 'not', 'want', 'to', 'be', 'banned', 'from', 'my', 'favorite', 'place', 'for', 'my', 'clumsiness', 'i', 'don', 't', 'think', 'i', 'can', 'live', 'without', 'true', 'food']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = cl.Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count:\n",
      " Counter({'i': 10, 'the': 10, 'and': 5, 'to': 5, 'have': 5, 'my': 4, 'as': 4, 'love': 3, 'place': 3, 'was': 3, 'kale': 3, 'this': 2, 'is': 2, 'into': 2, 'some': 2, 'highly': 2, 'food': 2, 'so': 2, 'we': 2, 'ordered': 2, 'aid': 2, 'gone': 2, 'since': 2, 'get': 2, 'salad': 2, 'a': 2, 'not': 2, 'can': 2, 'be': 2, 'boss': 1, 'who': 1, 'healthy': 1, 'eating': 1, 'recommended': 1, 'went': 1, 'over': 1, 'with': 1, 'skeptical': 1, 'friends': 1, 'one': 1, 'dinner': 1, 'enough': 1, 'convert': 1, 'them': 1, 'believers': 1, 'here': 1, 'good': 1, 'had': 1, 'shrimp': 1, 'dumplings': 1, 'onion': 1, 'tart': 1, 'starters': 1, 'shirataki': 1, 'noodles': 1, 'street': 1, 'tacos': 1, 'entrees': 1, 'also': 1, 'all': 1, 'of': 1, 'dishes': 1, 'were': 1, 'yummy': 1, 'back': 1, 'many': 1, 'times': 1, 'then': 1, 'never': 1, 'been': 1, 'disappointed': 1, 'after': 1, 'yoga': 1, 'or': 1, 'chicken': 1, 'chopped': 1, 'always': 1, 'once': 1, 'guy': 1, 'at': 1, 'next': 1, 'table': 1, 'uprooted': 1, 'whole': 1, 'plant': 1, 'by': 1, 'mistake': 1, 'on': 1, 'patio': 1, 'embarrassed': 1, 'his': 1, 'date': 1, 'ever': 1, 'very': 1, 'careful': 1, 'throw': 1, 'arms': 1, 'around': 1, 'quite': 1, 'clumsy': 1, 'sometimes': 1, 'do': 1, 'want': 1, 'banned': 1, 'from': 1, 'favorite': 1, 'for': 1, 'clumsiness': 1, 'don': 1, 't': 1, 'think': 1, 'live': 1, 'without': 1, 'true': 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Count:\\n\", wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Words:\n",
      "[('i', 10), ('the', 10), ('and', 5), ('to', 5), ('have', 5), ('my', 4), ('as', 4), ('love', 3), ('place', 3), ('was', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Top 10 Words:\")\n",
    "top_10_words = wc.most_common(10)\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7de18fb9733a6052242255807dbc8de0",
     "grade": true,
     "grade_id": "p1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 10),\n",
       " ('the', 10),\n",
       " ('and', 5),\n",
       " ('to', 5),\n",
       " ('have', 5),\n",
       " ('my', 4),\n",
       " ('as', 4),\n",
       " ('love', 3),\n",
       " ('place', 3),\n",
       " ('was', 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert_equal(type(top_10_words), list, msg='top_10_words should be a list')\n",
    "assert_equal(top_10_words, [('i', 10),('the', 10),('and', 5),('to', 5),('have', 5),('my', 4),\n",
    "                            ('as', 4),('love', 3),('place', 3),('was', 3)], msg='top_10_words list is not correct')\n",
    "print('Top 10 Words:')\n",
    "top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "434bca1099309ecd5e0405b9ae0fce6a",
     "grade": false,
     "grade_id": "cell-6cc2ae0e085cc156",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Problem 2: Prepare Data for Text Classification\n",
    "\n",
    "Create label and split text data set to training and testing set.\n",
    "\n",
    "For this problem you will use **data** and __rating__ created above.\n",
    "\n",
    "To solve this problem do the following:\n",
    "- Create **label** from __rating__. Set label to 1 if rating is 5 stars and 0 otherwise.(Hint: use lambda function: `label = rating.map(lambda x: 1 if x==5 else 0)`\n",
    "- Split data and label to training and testing using `train_test_split`.\n",
    " - Set test_size to 0.4.\n",
    " - Set random_state to 23.\n",
    " - Assign return values to **d_train, d_test, l_train, l_test**.\n",
    "\n",
    "After this problem, there are four new variable, **d_train, d_test, l_train** and  __l_test__ defined.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      5\n",
       "2      5\n",
       "3      5\n",
       "4      5\n",
       "      ..\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: stars, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = rating.map(lambda x: 1 if x==5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: stars, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f15662466dd8e222257cca5ac0f1103",
     "grade": false,
     "grade_id": "p2-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n",
    "d_train, d_test, l_train, l_test = train_test_split(data, label, test_size=0.4, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6568d7fb33f195d53c9017fd4503a78b",
     "grade": true,
     "grade_id": "p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(d_train), 600, msg='training set size is not correct')\n",
    "assert_equal(len(d_test), 400, msg='testing set size is not correct')\n",
    "assert_equal(l_train.iloc[1], 1, msg='l_train is not correct')\n",
    "assert_equal(l_train.iloc[100], 1, msg='l_train is not correct')\n",
    "assert_equal(l_test.iloc[0], 0, msg='l_test is not correct')\n",
    "assert_equal(l_test.iloc[100], 1, msg='l_test is not correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2c794a7877830313ce68afd60385c8",
     "grade": false,
     "grade_id": "cell-34d75d264e64349c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 3: Train a Multinomial Naive Bayes Model\n",
    "\n",
    "For this problem, use d_train, l_train, d_test and l_test created above.\n",
    "\n",
    "Your task for this problem is to build and train a `MultinomialNB` estimator to make predictions on the Yelp review dataset. \n",
    "\n",
    "To solve this problem do the following:\n",
    "- Create a `TfidfVectorizer` object, set `stop_words` to 'english'.\n",
    "- Fit the `TfidfVectorizer` objec with d_train\n",
    "- Transform d_train and d_test with the `TfidfVectorizer` object to get **train_dtm** and __test_dtm__\n",
    "- Create a `MultinomialNB` estimator **nb_model**. Accept default values for all hyperparameters.\n",
    "- Fit the `MultinomialNB` estimator using train_dtm and l_train.\n",
    "\n",
    "After this problem, there will be a trained multinomial Naive Bayes model **nb_model** define, as well as two document term matrices, __train_dtm, test_dtm__.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ddd6d5bdebabd0ff2142a2264ff24b9",
     "grade": false,
     "grade_id": "p3-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm = tfidf.transform(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<600x7361 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm = tfidf.transform(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<400x7361 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16990 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(train_dtm,l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ea46d268d814fbba3946b2c2e0472be",
     "grade": true,
     "grade_id": "p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(nb_model), type(MultinomialNB()), msg=\"nb_model is not defined as a MultinomialNB model\")\n",
    "assert_almost_equal(train_dtm[0, 132], 0.05808376842859404, msg=\"train_dtm is not correct\")\n",
    "assert_almost_equal(test_dtm[0, 157], 0.12459374859215833, msg=\"test_dtm is not correct\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f17cfbf8f755ba1ab46202bc08bb993b",
     "grade": false,
     "grade_id": "cell-5c71f0e397348902",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Problem 4: Get Text Classification Metrics\n",
    "\n",
    "For this problem, you will compute the classification metrics of the nb_model created in problem 3.  \n",
    "\n",
    "To complete this function, you must explicitly:\n",
    "\n",
    "- Apply nb_model `predict` function on test_dtm created in problem 3 to get predicted label, assign it to variable **l_pred**.\n",
    "- Use l_test and l_pred to calculate:\n",
    " - The mean accuracy score using `accuracy_score` function in `metrics` module and save the value to **mas_score**.\n",
    " - The classification report using `classification_report` function in `metrics` module and save it to variable **c_report**.\n",
    "\n",
    "After this problem, there will be two new variables, **mas_score** and __c_report__ defined.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9b7cf7de0d82e39928fd1d2c0d68da4",
     "grade": false,
     "grade_id": "p4-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# YOUR CODE HERE\n",
    "l_pred = nb_model.predict(test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas_score = metrics.accuracy_score(l_test,l_pred)\n",
    "mas_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_report = metrics.classification_report(l_test,l_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f34e040d3de1414e1824cfe6c4f3c61",
     "grade": true,
     "grade_id": "p4-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 88.5%\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       194\n",
      "           1       0.94      0.83      0.88       206\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.89      0.89      0.88       400\n",
      "weighted avg       0.89      0.89      0.88       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert_equal(mas_score, 0.885, msg='Accuracy score is not correct')\n",
    "assert_true('0.94' in c_report, msg='Classification report is not correct')\n",
    "assert_true('194' in c_report, msg='Classification report is not correct')\n",
    "print(f\"Accuracy Score: {mas_score*100:4.1f}%\")\n",
    "print(f\"Classification Report\\n{c_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "machine-learning-accounting-python",
   "graded_item_id": "w2uye",
   "launcher_item_id": "Bp0aI"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
